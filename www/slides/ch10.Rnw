% NOTE -- ONLY EDIT THE .Rnw FILE!!!  The .tex file is,
% likely to be overwritten.
\usepackage{SweaveSlides}
\title[Chapter 10]{Chapter 10: Inference for regression models}
%\subject{Models}
\SweaveOpts{engine=R,eps=FALSE,pdf=TRUE,width=10,height=6.5,strip.white=all,keep.source=TRUE}
\SweaveOpts{prefix=TRUE,prefix.string=figs/ch10,include=TRUE}
\begin{document}
\begin{frame}
  \titlepage
\end{frame}
\begin{frame}
  \frametitle{Outline}
  \tableofcontents[pausesections]
\end{frame}
<<preliminaries,echo=FALSE,results=hide>>=
options(width=60)
library(EngrExpt)
options(show.signif.stars = FALSE)
#lattice.options(default.theme = function() standard.theme(color=FALSE))
@ 
\newcommand{\rvy}{\ensuremath{\mathcal{Y}}}
\section[10.1 Regression lines]{10.1 Inference for a regression line}

\begin{frame}
  \frametitle{Section 10.1: Inference for a regression line}
  \begin{itemize}
  \item Recall that a simple linear regression model is
    \begin{displaymath}
      \rvy_i=\beta_0+\beta_1 x_i+\epsilon_i,\quad i=1,\dots,n
    \end{displaymath}
  \item The least squares estimates, $\widehat{\beta}_0$ and
    $\widehat{\beta}_1$, of the coefficients are functions of the data
    and hence are random variables.  We associate \Emph{standard
      errors} with these estimates.
  \item The text derives formulas for the variance of the estimators.
    The formulas can be interesting but do not easily extend to more
    complex models.  It is easier to simply read the standard error
    from the output.
  \item In the \code{R} output each coefficient estimate is
    accompanied by a \code{Std. Error} (standard error), a \code{t
      value} (the ratio of the estimate and its standard error) and a
    \code{Pr(>|t|)}, which is the p-value for the two-sided hypothesis
    test.  The \code{confint} extractor can be used to determine
    confidence intervals.
  \end{itemize}    
\end{frame}
\begin{frame}[fragile]
  \frametitle{Examples 10.1.1 and 10.1.2}
<<ex10.1.1show,eval=FALSE>>=
summary(fm1 <- lm(time ~ temp, timetemp,
                  subset = type == "Repaired"))
@   
<<ex10.1.1,echo=FALSE>>=
cat(paste(capture.output(summary(fm1 <- lm(time ~ temp,
                                           timetemp,
                                           subset = type == "Repaired")))[-(1:8)],
          collapse = "\n"), "\n")
@ 
<<ex10.1.2>>=
confint(fm1)
@ 
\begin{itemize}
\item The confidence interval ($[-2.099,-1.629]$) on $\beta_1$, the
  slope, is of interest.  The other confidence interval is not of
  interest because $\beta_0$ is meaningless for these data.
\end{itemize}
\end{frame}
\begin{frame}[fragile]
  \frametitle{Example 10.1.3}
\begin{center}
<<fbuildplt,fig=TRUE,echo=FALSE,height=3.5>>=
fm2 <- lm(gloss ~ build, fbuild)
print(xyplot(gloss ~ build, fbuild, type = c("g","p","r"),
             xlab = "Film build", ylab = "gloss", aspect = 1),
      split = c(1,1,3,1), more = TRUE)
print(xyplot(resid(fm2) ~ fitted(fm2),
             type = c("g", "p", "smooth")),
      split = c(2,1,3,1), more = TRUE)
print(qqmath(~resid(fm2), aspect = 1, ylab = "Residuals",
             type = c("g", "p"), xlab = "Standard normal quantiles"),
      split = c(3,1,3,1))
@   
\end{center}
<<fm2prt,echo=FALSE>>=
cat(paste(capture.output(summary(fm2))[-(1:9)],
          collapse = "\n"), "\n")

@ 
<<fm2confint>>=
confint(fm2)
@ 
\end{frame}
\begin{frame}
  \frametitle{Inference for coefficients}
  \begin{itemize}
  \item As seen in the previous slides, we can evaluate confidence
    intervals on the coefficients, $\beta_0$ and $\beta_1$, with the
    \code{confint} extractor function.
  \item The formula for the $(1-\alpha)$ confidence interval on
    $\beta_1$ is
    \begin{displaymath}
      \widehat{\beta}_1\pm t(\alpha/2, \nu)\,s_{\beta_1}
    \end{displaymath}
    where $\nu$ is the degrees of freedom for residuals ($n-2$ for a
    simple linear regression) and $s_{\beta_1}$ is the standard error
    for the coefficient.
  \item The observed $t$ statistic, $\widehat{\beta}_1/s_{\beta_1}$,
    is used to perform tests of the hypothesis $H_0:\beta_1=0$.  The
    p-value for the two-sided alternative is given in the coefficient
    table.  The p-value for the one-sided alternative that is
    indicated by the data will be half this value.  By ``indicated by
    the data'' I mean the alternative $H_a:\beta_1>0$, if
    $\widehat{\beta}_1>0$ and vice versa.
  \end{itemize}
\end{frame}
\begin{frame}[fragile]
  \frametitle{More on inference for coefficients}
  \begin{itemize}
  \item Testing $H_0:\beta_1=0$ versus the appropriate alternative is
    usually of interest.  Tests on $\beta_0$ are not always of
    interest as the intercept may not represent a meaningful response.
  \item If you want only the table of coefficients, standard errors
    and test statistics, you can extract it using
  \end{itemize}
<<coeftab>>=
coef(summary(fm1))
@ 
\end{frame}

